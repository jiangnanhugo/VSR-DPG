{
   "task" : {
      // Metric to be used for the reward function. See regression.py for
      // supported metrics.
      "metric" : "inv_nrmse",
      "metric_params" : [1.0],
      // NRMSE threshold for early stopping. This is useful for noiseless
      // benchmark problems when DSO discovers the true solution.
      "threshold" : 1e-12,

      // With protected=false, floating-point errors (e.g. log of negative
      // number) will simply returns a minimal reward. With protected=true,
      // "protected" functions will prevent floating-point errors, but may
      // introduce discontinuities in the learned functions.      
      "protected" : false,
      "normalize_variance" : false
   },

   // Only the key training hyperparameters are listed here. See
   // config_common.json for the full list.
   "training" : {
      "n_epochs": 100,
      "dataset_size":15000,
      "batch_size" : 500,
      "epsilon" : 0.02
   },

   // Only the key RNN controller hyperparameters are listed here. See
   // config_common.json for the full list.
   "expression_decoder" : {
      "learning_rate": 0.0025,
      "entropy_weight" : 0.03,
      "entropy_gamma" : 0.7,
      // Priority queue training hyperparameters.
      "pqt" : true,
      "pqt_k" : 10,
      "pqt_batch_size" : 1,
      "pqt_weight" : 200.0,
      "pqt_use_pg" : false
   }
}
